{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "305ddc76-7835-4fd0-b0f6-ec287d93d2d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3704516a-4f34-4937-8250-cda36e675f6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after merging node and graph datasets:\nIndex(['~id', '~labels', 'fileName', 'errorMessage', 'fileSource',\n       'total_chunks', 'processingTime', 'createdAt', 'fileSize', 'nodeCount',\n       'model', 'processed_chunk', 'fileType', 'relationshipCount',\n       'is_cancelled', 'status', 'updatedAt', 'content_offset', 'page_number',\n       'length', 'id', 'text', 'position', 'embedding', 'description',\n       '~start_node_id', '~start_node_labels', '~start_node_property_fileName',\n       '~start_node_property_content_offset',\n       '~start_node_property_page_number', '~start_node_property_length',\n       '~start_node_property_id', '~start_node_property_text',\n       '~start_node_property_position', '~start_node_property_embedding',\n       '~relationship_type', '~end_node_id', '~end_node_labels',\n       '~end_node_property_fileName', '~end_node_property_errorMessage',\n       '~end_node_property_fileSource', '~end_node_property_total_chunks',\n       '~end_node_property_processingTime', '~end_node_property_createdAt',\n       '~end_node_property_fileSize', '~end_node_property_nodeCount',\n       '~end_node_property_model', '~end_node_property_processed_chunk',\n       '~end_node_property_fileType', '~end_node_property_relationshipCount',\n       '~end_node_property_is_cancelled', '~end_node_property_status',\n       '~end_node_property_updatedAt', '~start_node_property_errorMessage',\n       '~start_node_property_fileSource', '~start_node_property_total_chunks',\n       '~start_node_property_processingTime', '~start_node_property_createdAt',\n       '~start_node_property_fileSize', '~start_node_property_nodeCount',\n       '~start_node_property_model', '~start_node_property_processed_chunk',\n       '~start_node_property_fileType',\n       '~start_node_property_relationshipCount',\n       '~start_node_property_is_cancelled', '~start_node_property_status',\n       '~start_node_property_updatedAt', '~end_node_property_content_offset',\n       '~end_node_property_page_number', '~end_node_property_length',\n       '~end_node_property_id', '~end_node_property_text',\n       '~end_node_property_position', '~end_node_property_embedding',\n       '~end_node_property_description'],\n      dtype='object')\nColumns after merging relationships with node data:\nIndex(['~id_x', '~start_node_id', '~end_node_id', '~relationship_type',\n       '~id_y', '~labels_start', '~start_node_property_text_start',\n       '~start_node_property_embedding_start', '~id', '~labels_end',\n       '~start_node_property_text_end', '~start_node_property_embedding_end'],\n      dtype='object')\nFirst few rows of the cleaned and merged dataset:\n   ~start_node_id  ...  ~start_node_property_embedding_end\n0               1  ...                                 NaN\n1               1  ...                                 NaN\n2               1  ...                                 NaN\n3               1  ...                                 NaN\n4               1  ...                                 NaN\n\n[5 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "relationship_df = pd.read_csv('relationship-export.csv')\n",
    "node_df = pd.read_csv('node-export.csv')\n",
    "graph_df = pd.read_csv('graph-export.csv')\n",
    "\n",
    "# Merge node properties\n",
    "merged_node_df = pd.merge(node_df, graph_df, how='outer', left_on='~id', right_on='~start_node_id', suffixes=('_node', '_graph'))\n",
    "\n",
    "# Inspect the columns\n",
    "print(\"Columns after merging node and graph datasets:\")\n",
    "print(merged_node_df.columns)\n",
    "\n",
    "# Select only the existing columns\n",
    "columns_to_keep = ['~id', '~labels', \n",
    "                   'text_node', 'embedding_node', 'position_node', \n",
    "                   'length_node', 'content_offset_node', 'page_number_node', \n",
    "                   '~start_node_property_text', '~start_node_property_embedding']\n",
    "\n",
    "# Filter columns dynamically\n",
    "columns_to_keep_existing = [col for col in columns_to_keep if col in merged_node_df.columns]\n",
    "\n",
    "# Create the cleaned node dataframe\n",
    "cleaned_node_df = merged_node_df[columns_to_keep_existing]\n",
    "\n",
    "# Merge the cleaned node dataset with the relationship dataset using the '~start_node_id' and '~end_node_id'\n",
    "# attach the corresponding node properties to each relationship\n",
    "merged_relationship_df = pd.merge(relationship_df, cleaned_node_df, how='left', left_on='~start_node_id', right_on='~id')\n",
    "merged_relationship_df = pd.merge(merged_relationship_df, cleaned_node_df, how='left', left_on='~end_node_id', right_on='~id', suffixes=('_start', '_end'))\n",
    "\n",
    "# Inspect the columns after merging the relationships and node data\n",
    "print(\"Columns after merging relationships with node data:\")\n",
    "print(merged_relationship_df.columns)\n",
    "\n",
    "# select the columns for start and end node text and embeddings\n",
    "final_columns_to_keep = ['~start_node_id', '~end_node_id', '~relationship_type']\n",
    "\n",
    "# Filter columns that start with 'text_' or 'embedding_' for both start and end nodes\n",
    "final_columns_to_keep += [col for col in merged_relationship_df.columns if 'text_' in col or 'embedding_' in col]\n",
    "\n",
    "# Filter the final merged DataFrame\n",
    "final_merged_df = merged_relationship_df[final_columns_to_keep]\n",
    "\n",
    "# Clean up any remaining NaN or unnecessary rows\n",
    "final_cleaned_df = final_merged_df.dropna(subset=['~start_node_id', '~end_node_id'])\n",
    "\n",
    "# Save dataset\n",
    "final_cleaned_df.to_csv('final_merged_cleaned_dataset.csv', index=False)\n",
    "\n",
    "# Display\n",
    "print(\"First few rows of the cleaned and merged dataset:\")\n",
    "print(final_cleaned_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56a470b8-0129-4287-9eb3-a3bdcf422df7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Knowledge Graph Construction and Querying**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99849032-eb3d-4868-95b6-c0642efdf5ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the final dataset:\nIndex(['~start_node_id', '~end_node_id', '~relationship_type',\n       '~start_node_property_text_start',\n       '~start_node_property_embedding_start', '~start_node_property_text_end',\n       '~start_node_property_embedding_end'],\n      dtype='object')\nNode 1 text: Definitions accepted offer is acceptance is entering a written agreement the offer of placement is accepted within the nominated tim navigate accepted offers offer status a ie accepted includes cancelled studylink ltigtpending conditionsltigt created by australian government department of education esos framework admission is students admission into a program covering the point of admission and record of ongoing status of their adm does not include cancelled ltigtall conditions have been metltigt created by australian government dictionary advanced diploma is the purpose of the advanced diploma qualification type is to qualify individuals who apply specialised uk level 4 equivalent qualification knowledge of the underlying concepts and principles associated with their areas of study an ability to present alumni is a graduate or former student when a student completes their studies they become an alumni of the institution applicant is data relating to a person who has applied for at least one of the programs offered by the institution created b application is applicants instruction to be considered for a programme of study by submitting an application form\nNode 1 embedding: ['-0.028172967955470085','0.019017869606614113','0.026219958439469337','0.01593800261616707','0.020942941308021545','0.006162898149341345','0.050998784601688385','0.020823443308472633','-0.08031544089317322','0.06614826619625092','0.05613984167575836','-0.04334217682480812','-0.004547140095382929','-0.039915744215250015','-0.0013324860483407974','-0.044259924441576004','0.01040305383503437','-0.09709882736206055','0.015587955713272095','-0.01984531059861183','-0.011198262684047222','0.07321720570325851','-0.022854968905448914','-0.022676102817058563','0.007844693027436733','-0.03618866950273514','-0.023092595860362053','-0.02456909604370594','0.06899388134479523','0.05259081721305847','0.037106625735759735','0.07101025432348251','0.02679397352039814','0.04647974669933319','0.00358519796282053','-0.007929932326078415','-0.023452702909708023','-0.04702136665582657','0.007975861430168152','-0.04971747100353241','-0.05195419862866402','-0.041134510189294815','0.0020744637586176395','0.009722082875669003','0.03904532641172409','-0.050599079579114914','-0.07920722663402557','-0.0674157589673996','-0.06426838785409927','0.005212351214140654','0.014982000924646854','-0.022102363407611847','-0.0199865885078907','-0.02292484976351261','-0.09869107604026794','0.0532853789627552','-0.0653739869594574','-0.04439409449696541','-0.07949570566415787','-0.06617601215839386','-0.0069352202117443085','-0.015000686049461365','-0.0607023686170578','0.0314781628549099','-0.003605138510465622','-0.024189528077840805','-0.026839179918169975','-0.04342562332749367','0.09071459621191025','-0.0035777834709733725','-0.015132584609091282','-0.03249354287981987','-0.09482992440462112','0.029330536723136902','0.001668433891609311','-0.03281259164214134','0.05656290054321289','0.07385662198066711','0.03397778421640396','0.04935922101140022','0.043030157685279846','0.04670464247465134','-0.03642893582582474','-0.14043597877025604','0.04205866530537605','-0.06265056133270264','-0.020831039175391197','-0.02439059689640999','0.016388989984989166','0.04035288095474243','0.101197250187397','-0.08076498657464981','-0.029207447543740273','0.04300333932042122','0.09132813662290573','-0.07686923444271088','0.03650831803679466','-0.018356991931796074','0.013030221685767174','0.020683029666543007','-0.04411981999874115','-0.009299552999436855','-0.08420335501432419','0.050536029040813446','-0.10166516155004501','-0.050341904163360596','0.06724032759666443','-0.03411044180393219','0.05496739223599434','-0.06936823576688766','-0.05308985337615013','-0.0904928669333458','0.0054051862098276615','-0.006809370592236519','-0.03911710903048515','0.0581764280796051','0.005475470330566168','0.03100750595331192','0.07497861236333847','-0.03301405906677246','0.0008664622437208891','0.06999483704566956','0.03538576140999794','-0.09988804906606674','-0.03260250389575958','-0.14358772337436676','-0.050529394298791885','6.646097388071392e-33','-0.016791144385933876','0.011120593175292015','-0.09297961741685867','0.05951761081814766','0.00042329408461228013','0.035453539341688156','-0.02880859561264515','-0.016297442838549614','0.002513897605240345','0.028537122532725334','-0.003349883249029517','0.08530304580926895','-0.003950722515583038','0.07460566610097885','0.048818688839673996','0.05058910325169563','0.02111244760453701','0.1367010772228241','0.05821754038333893','0.06559091806411743','0.055047884583473206','-0.015854083001613617','0.03541262075304985','-0.02087322063744068','-0.03631691634654999','0.03504912182688713','-0.01690933294594288','0.019419344142079353','0.053641706705093384','0.005908680614084005','0.04234514757990837','-0.03871466964483261','-0.0751693919301033','-0.02572016604244709','-0.01136506162583828','0.023500530049204826','0.023273976519703865','-0.07599278539419174','0.07547155767679214','-0.08826064318418503','-0.03379078209400177','0.020414628088474274','0.006106698419898748','-0.01003993209451437','0.01650831662118435','-0.006883790250867605','-0.0027791541069746017','-0.0567048005759716','0.09353545308113098','0.11432981491088867','-0.016764555126428604','-0.054491665214300156','-0.06956464797258377','-0.10966577380895615','-0.016337038949131966','0.061160773038864136','-0.025687700137495995','0.0859609991312027','-0.050959210842847824','-0.017193002626299858','-0.0009402759023942053','-0.03661985322833061','-0.05237468704581261','-0.054956987500190735','-0.06028088182210922','-0.020640449598431587','0.03985082730650902','-0.13871070742607117','0.090415820479393','-0.03127922862768173','-0.09536673128604889','-0.08613455295562744','0.01924191601574421','0.060342058539390564','0.008108790032565594','-0.037503354251384735','-0.008128066547214985','0.054275669157505035','0.02714899741113186','0.0009112230036407709','-0.020070280879735947','0.01067533902823925','-0.043637365102767944','-0.06899987161159515','0.07563837617635727','0.04012152552604675','0.01695588231086731','-0.05143645033240318','0.08890791982412338','-0.02985156513750553','0.012027683667838573','-0.008452984504401684','-0.07812821865081787','0.09292788803577423','0.09297580271959305','-8.462041468839971e-33','0.10267551988363266','0.022341115400195122','-0.07349091023206711','-0.007120866794139147','0.027701547369360924','0.038732316344976425','0.06964611262083054','-0.01800842583179474','0.05589167773723602','-0.04050854593515396','0.031220924109220505','0.019761011004447937','0.02241053245961666','-0.012230566702783108','-0.05724877864122391','-0.03969210386276245','-0.006263649556785822','0.027603769674897194','-0.0006067108479328454','0.07213736325502396','0.02695477567613125','-0.012239832431077957','0.03718226030468941','-0.01647319458425045','0.015634309500455856','-0.02220294252038002','0.008841763250529766','-0.009022998623549938','-0.07861166447401047','-0.0824630856513977','0.02816709689795971','-0.038002077490091324','-0.12508289515972137','0.025387102738022804','-0.02926637977361679','-0.06894189119338989','0.08867664635181427','0.041050542145967484','-0.06044916436076164','0.11204636096954346','0.07942859828472137','-0.013412670232355595','0.005626242607831955','0.03419049456715584','-0.036780014634132385','0.009824912063777447','0.0541062094271183','-0.020986203104257584','0.07056805491447449','-0.02695431560277939','0.029234973713755608','0.05114981159567833','0.09266591817140579','0.00983204785734415','0.07923812419176102','-0.02796033024787903','0.0070516569539904594','-0.062493763864040375','-0.033598270267248154','0.03749074786901474','0.15367491543293','0.04969237744808197','0.02233101800084114','0.03052898682653904','0.032642610371112823','-0.05335911735892296','-0.03734061121940613','0.014162273146212101','-0.0862637460231781','0.0464802011847496','0.011372528038918972','-0.08328118920326233','0.008130593225359917','-0.08753093332052231','0.07870100438594818','-0.030737590044736862','0.0142895532771945','-0.02050360105931759','0.007598144467920065','-0.05933069810271263','-0.09253933280706406','0.06454267352819443','0.005420327186584473','0.05864011496305466','0.021948231384158134','-0.04810124263167381','0.001998470863327384','0.03037646785378456','0.07047386467456818','0.0076115974225103855','0.0247584767639637','-0.04600316286087036','-0.0019120711367577314','-0.030229318886995316','-0.008705844171345234','-5.027374072597013e-8','-0.04071991890668869','-0.029684126377105713','-0.08673864603042603','-0.0771213173866272','0.020334864035248756','0.04513343796133995','-0.07666192203760147','-0.0630277544260025','0.030869843438267708','-0.05220946669578552','-0.03902922198176384','-0.007453264202922583','-0.06933744996786118','-0.04649513587355614','0.04948916658759117','0.07018521428108215','-0.034859295934438705','0.0332380086183548','-0.007994349114596844','0.08027013391256332','-0.024038419127464294','-0.023684188723564148','0.012634147889912128','0.011562402360141277','0.01952526345849037','0.06692615896463394','0.024686332792043686','-0.010116239078342915','-0.017951954156160355','0.07203292101621628','-0.04266025498509407','-0.003663969924673438','0.12022440880537033','-0.03278873860836029','0.014004040509462357','0.001641793642193079','0.06212540343403816','-0.0434437058866024','-0.01906943880021572','0.027162889018654823','-0.033816538751125336','-0.04467558115720749','0.05736628547310829','0.027251768857240677','0.002545261988416314','0.08562608808279037','-0.054556164890527725','0.04880082607269287','-0.045899830758571625','-0.011643067933619022','-0.06745605915784836','-0.01696864329278469','-0.02725241892039776','-0.011685024946928024','-0.03393111377954483','-0.022047385573387146','-0.016292335465550423','-0.008921136148273945','-0.03926948830485344','-0.05754469707608223','0.08311387896537781','-0.028707755729556084','0.020254988223314285','0.00609670439735055']\nNodes connected to 1: [0, 2, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "final_cleaned_df = pd.read_csv('final_merged_cleaned_dataset.csv')\n",
    "\n",
    "# Inspect the columns to find the correct names for text and embedding columns\n",
    "print(\"Columns in the final dataset:\")\n",
    "print(final_cleaned_df.columns)\n",
    "\n",
    "# Create an empty directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# text and embeddings\n",
    "# Convert text and embedding values to strings, using placeholders for None values\n",
    "for index, row in final_cleaned_df.iterrows():\n",
    "    # Convert to string or use empty string if None\n",
    "    start_text = str(row.get('~start_node_property_text_start', ''))\n",
    "    start_embedding = str(row.get('~start_node_property_embedding_start', ''))\n",
    "    \n",
    "    end_text = str(row.get('~start_node_property_text_end', ''))\n",
    "    end_embedding = str(row.get('~start_node_property_embedding_end', ''))\n",
    "    \n",
    "    # Add start node with its properties\n",
    "    G.add_node(row['~start_node_id'], text=start_text, embedding=start_embedding)\n",
    "    \n",
    "    # Add end node with its properties\n",
    "    G.add_node(row['~end_node_id'], text=end_text, embedding=end_embedding)\n",
    "\n",
    "# Add edges (relationships) between nodes\n",
    "for index, row in final_cleaned_df.iterrows():\n",
    "    G.add_edge(row['~start_node_id'], row['~end_node_id'], relationship=row['~relationship_type'])\n",
    "\n",
    "# Save the graph structure\n",
    "nx.write_gml(G, 'kg_graph.gml')\n",
    "\n",
    "# Querying the graph\n",
    "# Query the graph to find relationships or node information\n",
    "example_node = final_cleaned_df.iloc[0]['~start_node_id']  \n",
    "print(f\"Node {example_node} text:\", G.nodes[example_node]['text'])\n",
    "print(f\"Node {example_node} embedding:\", G.nodes[example_node]['embedding'])\n",
    "\n",
    "connected_nodes = list(G.successors(example_node))\n",
    "print(f\"Nodes connected to {example_node}:\", connected_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a2ff633-cd9f-4195-99b0-0093b29e05e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Import Libraries and Define Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82000f6a-4786-42c5-bbe3-d3a0cbc2065e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas in /local_disk0/.ephemeral_nfs/envs/pythonEnv-8e3b2c65-33f9-4290-a105-d1d8a4c06e23/lib/python3.11/site-packages (0.1.21)\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-8e3b2c65-33f9-4290-a105-d1d8a4c06e23/lib/python3.11/site-packages (from ragas) (2.1.2)\nRequirement already satisfied: datasets in /databricks/python3/lib/python3.11/site-packages (from ragas) (2.19.1)\nRequirement already satisfied: tiktoken in /local_disk0/.ephemeral_nfs/envs/pythonEnv-8e3b2c65-33f9-4290-a105-d1d8a4c06e23/lib/python3.11/site-packages (from ragas) (0.8.0)\nRequirement already satisfied: langchain<0.3 in /databricks/python3/lib/python3.11/site-packages (from ragas) (0.1.20)\nRequirement already satisfied: langchain-core<0.3 in /databricks/python3/lib/python3.11/site-packages (from ragas) (0.1.52)\nRequirement already satisfied: langchain-community<0.3 in /databricks/python3/lib/python3.11/site-packages (from ragas) (0.0.38)\nRequirement already satisfied: langchain-openai in /local_disk0/.ephemeral_nfs/envs/pythonEnv-8e3b2c65-33f9-4290-a105-d1d8a4c06e23/lib/python3.11/site-packages (from ragas) (0.1.7)\nRequirement already satisfied: openai>1 in /databricks/python3/lib/python3.11/site-packages (from ragas) (1.35.3)\nRequirement already satisfied: pysbd>=0.3.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-8e3b2c65-33f9-4290-a105-d1d8a4c06e23/lib/python3.11/site-packages (from ragas) (0.3.4)\nRequirement already satisfied: nest-asyncio in /databricks/python3/lib/python3.11/site-packages (from ragas) (1.5.6)\nRequirement already satisfied: appdirs in /local_disk0/.ephemeral_nfs/envs/pythonEnv-8e3b2c65-33f9-4290-a105-d1d8a4c06e23/lib/python3.11/site-packages (from ragas) (1.4.4)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.3->ragas) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.3->ragas) (1.4.39)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.3->ragas) (3.8.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.3->ragas) (0.6.7)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.3->ragas) (0.0.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.3->ragas) (0.1.63)\nCollecting numpy (from ragas)\n  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/61.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.0/61.0 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.3->ragas) (1.10.6)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.3->ragas) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.3->ragas) (8.2.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.11/site-packages (from langchain-core<0.3->ragas) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /databricks/python3/lib/python3.11/site-packages (from langchain-core<0.3->ragas) (23.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.11/site-packages (from openai>1->ragas) (3.5.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>1->ragas) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from openai>1->ragas) (0.27.0)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.11/site-packages (from openai>1->ragas) (1.2.0)\nRequirement already satisfied: tqdm>4 in /databricks/python3/lib/python3.11/site-packages (from openai>1->ragas) (4.65.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /databricks/python3/lib/python3.11/site-packages (from openai>1->ragas) (4.10.0)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from datasets->ragas) (3.13.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /databricks/python3/lib/python3.11/site-packages (from datasets->ragas) (14.0.1)\nRequirement already satisfied: pyarrow-hotfix in /databricks/python3/lib/python3.11/site-packages (from datasets->ragas) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from datasets->ragas) (0.3.6)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.11/site-packages (from datasets->ragas) (1.5.3)\nRequirement already satisfied: xxhash in /databricks/python3/lib/python3.11/site-packages (from datasets->ragas) (3.4.1)\nRequirement already satisfied: multiprocess in /databricks/python3/lib/python3.11/site-packages (from datasets->ragas) (0.70.14)\nRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /databricks/python3/lib/python3.11/site-packages (from datasets->ragas) (2023.5.0)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /databricks/python3/lib/python3.11/site-packages (from datasets->ragas) (0.23.4)\nRequirement already satisfied: regex>=2022.1.18 in /databricks/python3/lib/python3.11/site-packages (from tiktoken->ragas) (2022.7.9)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.3->ragas) (22.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.3->ragas) (2.0.4)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.3->ragas) (6.0.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.3->ragas) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.3->ragas) (1.8.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.3->ragas) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.3->ragas) (1.2.0)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.4)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /databricks/python3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.3->ragas) (3.21.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.3->ragas) (0.9.0)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2023.7.22)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3->ragas) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /databricks/python3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.3->ragas) (3.10.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.3->ragas) (1.26.16)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.3->ragas) (2.0.1)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.11/site-packages (from pandas->datasets->ragas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas->datasets->ragas) (2022.7)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->ragas) (1.16.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.3->ragas) (0.4.3)\nDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/18.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/18.3 MB\u001B[0m \u001B[31m84.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.7/18.3 MB\u001B[0m \u001B[31m97.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.7/18.3 MB\u001B[0m \u001B[31m112.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m14.8/18.3 MB\u001B[0m \u001B[31m115.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m118.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m118.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m118.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m118.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m118.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m118.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m118.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m118.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m118.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m118.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.3/18.3 MB\u001B[0m \u001B[31m23.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.1.2\n    Uninstalling numpy-2.1.2:\n      Successfully uninstalled numpy-2.1.2\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\nnumba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed numpy-1.26.4\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb182fe3-d4bf-4757-ab04-b2fbedf87e97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /local_disk0/.ephemeral_nfs/envs/pythonEnv-8e3b2c65-33f9-4290-a105-d1d8a4c06e23/lib/python3.11/site-packages (1.9.0)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-8e3b2c65-33f9-4290-a105-d1d8a4c06e23/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.11/site-packages (from faiss-cpu) (23.2)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "274a0e66-4dee-47ab-af5c-ecaa9715a092",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import time\n",
    "import psutil\n",
    "from functools import lru_cache\n",
    "from ragas.metrics import context_precision, faithfulness, answer_relevancy, context_recall\n",
    "from ragas import evaluate\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Document class definition\n",
    "class Document:\n",
    "    def __init__(self, page_content, metadata=None):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata or {}\n",
    "\n",
    "# Function to load definitions from a text file\n",
    "def load_definitions(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return [line.strip() for line in file if line.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486db392-8b96-4111-962c-4a5f944662fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Knowledge Graph & FAISS Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90c62a32-62dd-4f3f-8458-27232ed30dfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# KG and FAISS retriever class\n",
    "class KGAndFAISSRetriever:\n",
    "    def __init__(self, definitions, kg, num_retrieved_docs=5):\n",
    "        # FAISS retrieval setup\n",
    "        all_documents = [Document(definition) for definition in definitions]\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.db = FAISS.from_documents(all_documents, embeddings)\n",
    "        self.retriever = self.db.as_retriever(search_kwargs={\"k\": num_retrieved_docs})\n",
    "        \n",
    "        # Knowledge Graph (KG)\n",
    "        self.kg = kg\n",
    "        self.num_retrieved_docs = num_retrieved_docs\n",
    "\n",
    "    def search(self, query):\n",
    "        # FAISS retrieval\n",
    "        faiss_docs = self.retriever.get_relevant_documents(query)\n",
    "        # KG retrieval\n",
    "        kg_info = self.query_kg(query)\n",
    "        return faiss_docs, kg_info\n",
    "\n",
    "    def query_kg(self, query):\n",
    "        # Query the KG by matching text\n",
    "        relevant_nodes = []\n",
    "        for node in self.kg.nodes:\n",
    "            if query.lower() in self.kg.nodes[node]['text'].lower():\n",
    "                relevant_nodes.append(self.kg.nodes[node]['text'])\n",
    "        return \" \".join(relevant_nodes[:self.num_retrieved_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a0612f4-8b20-4b53-8e4c-949ed7f7f347",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Flan-T5 Assistant Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d19a4d8-3130-4852-a357-5d20737b76f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Flan-T5 assistant class for generation\n",
    "class FlanT5Assistant:\n",
    "    def __init__(self, model_name='google/flan-t5-small'):\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    def create_prompt(self, query, retrieved_info):\n",
    "        return (f\"Explain the concept or answer the question in a detailed manner using simple words and examples.\\n\"\n",
    "                f\"Instruction: {query}\\n\"\n",
    "                f\"Relevant information: {retrieved_info}\\n\"\n",
    "                f\"Output:\")\n",
    "\n",
    "    def generate_reply(self, query, retrieved_info):\n",
    "        prompt = self.create_prompt(query, retrieved_info)\n",
    "        input_ids = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
    "        outputs = self.model.generate(input_ids, max_length=100, num_beams=5, early_stopping=True)\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b24929f-8adc-4ff7-ab0b-f8890b9eb802",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**T5 Assistant Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b59bf3f3-458d-49cb-b3e0-5651669b9f3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# T5 Assistant class for generation\n",
    "class T5Assistant:\n",
    "    def __init__(self, model_name='t5-small'):\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    def create_prompt(self, query, retrieved_info):\n",
    "        return (f\"Explain the concept or answer the question in a detailed manner using simple words and examples.\\n\"\n",
    "                f\"Instruction: {query}\\n\"\n",
    "                f\"Relevant information: {retrieved_info}\\n\"\n",
    "                f\"Output:\")\n",
    "\n",
    "    def generate_reply(self, query, retrieved_info):\n",
    "        prompt = self.create_prompt(query, retrieved_info)\n",
    "        input_ids = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
    "        outputs = self.model.generate(input_ids, max_length=100, num_beams=5, early_stopping=True)\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f031c141-75be-40f9-b293-70a353a7e18c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eade04ac-0238-4d11-9c29-9842e815923d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate BLEU score\n",
    "def calculate_bleu(reference, candidate):\n",
    "    reference = [reference.split()]\n",
    "    candidate = candidate.split()\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
    "\n",
    "# Print memory usage\n",
    "def print_memory_usage():\n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    print(f\"Memory Usage: {memory_info.rss / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# LRU cache to speed up repeated queries\n",
    "@lru_cache(maxsize=10)\n",
    "def cached_generate_reply(assistant, query, retrieved_info):\n",
    "    return assistant.generate_reply(query, retrieved_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b10b827-a2fa-4dc0-b4f4-45e45d574f5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Process Queries and Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3f84ea3-c378-4ce4-b4ac-174080d10acb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with Flan-T5-Small Model\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the definition of 'Articulation'?\nGenerated Reply (Flan-T5):\nKG\nReference Answer:\nArticulation is Arrangements enabling students to progress from a completed qualification to another with admission and/or credit in a defined qualification pathway  Or qualifying to enter the Bachelor program. created by TEQSA\nBLEU Score: 0\nMemory Usage: 2425.71 MB\nTime taken for this query: 3.06 seconds\n\nQuery: Which accreditation framework is mentioned under the definition of 'Doctoral Degree'?\nGenerated Reply (Flan-T5):\nprofessional or highly skilled work\nReference Answer:\n\"Doctoral Degree is Course with major research component: comprised of two-thirds or more research leading to a thesis/dissertation OR qualifies individuals who apply a substantial body of knowledge to research, investigate and develop new knowledge, in one or more fields of investigation, scholarship or professional practice. Two forms of Doctoral Degree with the same descriptor within the Doctoral Degree qualification type: the Doctoral Degree (Research) and the Doctoral Degree (Professional). Research is the defining characteristic of all Doctoral Degree qualifications. The research Doctoral Degree (typically referred to as a Doctor of Philosophy) makes a significant and original contribution to knowledge; the professional Doctoral Degree (typically titled Doctor of [field of study]) makes a significant and original contribution to knowledge in the context of professional practice. Learning outcomes and research may differ between the different forms of Doctoral Degree qualifications. Designed and accredited to enable graduates to demonstrate the learning outcomes specified in the level 10 criteria and the Doctoral Degree. created by AQF (Australian Qualifications Framework)\"\nBLEU Score: 5.62876404963307e-16\nMemory Usage: 2392.84 MB\nTime taken for this query: 2.62 seconds\n\nQuery: Which organization is referenced in the definition of 'Assessment'?\nGenerated Reply (Flan-T5):\nAssessment\nReference Answer:\n\"Assessment is Assessment is the process of appraising, evaluating and making a judgment about someone's knowledge, skills and ability in order to determine if they have met with and achieved the designated learning outcomes of individual units of study.\nBLEU Score: 3.1391327920480296e-17\nMemory Usage: 2428.57 MB\nTime taken for this query: 2.91 seconds\n\nQuery: What is the difference between a 'Bachelor Degree' and a 'Bachelor Honours Degree' with reference to qualification level in the AQF?\nGenerated Reply (Flan-T5):\nBachelor Honours Degree\nReference Answer:\n\"Bachelor Honours Degree is Qualifies individuals who apply a body of knowledge in a specific context to undertake professional work and as a pathway for research and further learning. Bachelor Honours Degree qualifications are located at level 8 of the Australian Qualifications Framework. Qualifications must be designed and accredited to enable graduates to demonstrate the learning outcomes expressed as knowledge, skills and the application of knowledge and skills specified in the level 8 criteria and the Bachelor Degree descriptor. created by AQF (Australian Qualifications Framework)\"\nBLEU Score: 7.753455067999575e-13\nMemory Usage: 2434.29 MB\nTime taken for this query: 2.57 seconds\n\nQuery: If a student studies in a foreign educational institution and is not a citizen or permanent resident of Australia, what term would the dataset use to categorize them as per the definitions?\nGenerated Reply (Flan-T5):\nKG\nReference Answer:\nStudents who study in foreign educational institutions. In Australia you are considered to be an overseas student if you’re not an Australian citizen\nBLEU Score: 0\nMemory Usage: 2456.20 MB\nTime taken for this query: 2.46 seconds\n\nQuery: If a student completes a Certificate III and intends to directly pursue a Bachelor Degree, which concept from this dataset would likely apply to their transition?\nGenerated Reply (Flan-T5):\nBachelor degree\nReference Answer:\n\"Certificate III is Qualifies individuals who apply a broad range of knowledge and skills in varied contexts to undertake skilled work and as a pathway for further learning. Designed and accredited to enable graduates to demonstrate the learning outcomes expressed as knowledge, skills and the application of knowledge and skills specified in the level 3 criteria and the Certificate III descriptor. created by AQF (Australian Qualifications Framework)\"\nBLEU Score: 0\nMemory Usage: 2494.87 MB\nTime taken for this query: 2.53 seconds\n\nQuery: Describe the relationship between 'Foundation Course' and 'Pathway Course' based on their respective definitions.\nGenerated Reply (Flan-T5):\nFoundation Course)\nReference Answer:\n\"Pathway Course is An award or non-award course/program that a student completes ahead of access to a subsequent course (e.g. ELICOS ahead of Foundation Program; diploma ahead of degree, undergraduate degree ahead of postgraduate degree etc).  Pathway courses/programs typically include: ELICOS, Foundation, Diploma, Pre-Masters, but may also include other sub-bachelor courses such as associate degrees. created by TEQSA\"\nBLEU Score: 4.670287398280555e-14\nMemory Usage: 2502.45 MB\nTime taken for this query: 2.66 seconds\n\nQuery: What percentage of modules studied that received a pass grade is referred to in the dataset, and under what name is this metric captured?\nGenerated Reply (Flan-T5):\nAssessment Result is the mark given for an assessment item created by The University of Western Australia.\nReference Answer:\nAssessment Result is The mark given for an assessment item created by The University of Western Australia\nBLEU Score: 0.762465858623486\nMemory Usage: 2453.82 MB\nTime taken for this query: 3.09 seconds\n\nQuery: If a student qualifies under the 'Doctoral Degree (Research)' category of the AQF, what learning outcome is significant in their qualification process?\nGenerated Reply (Flan-T5):\nDiploma\nReference Answer:\n\"Doctoral Degree is Course with major research component: comprised of two-thirds or more research leading to a thesis/dissertation OR qualifies individuals who apply a substantial body of knowledge to research, investigate and develop new knowledge, in one or more fields of investigation, scholarship or professional practice. Two forms of Doctoral Degree with the same descriptor within the Doctoral Degree qualification type: the Doctoral Degree (Research) and the Doctoral Degree (Professional). Research is the defining characteristic of all Doctoral Degree qualifications. The research Doctoral Degree (typically referred to as a Doctor of Philosophy) makes a significant and original contribution to knowledge; the professional Doctoral Degree (typically titled Doctor of [field of study]) makes a significant and original contribution to knowledge in the context of professional practice. Learning outcomes and research may differ between the different forms of Doctoral Degree qualifications. Designed and accredited to enable graduates to demonstrate the learning outcomes specified in the level 10 criteria and the Doctoral Degree. created by AQF (Australian Qualifications Framework)\"\nBLEU Score: 0\nMemory Usage: 2498.68 MB\nTime taken for this query: 2.63 seconds\n\nQuery: Based on the definitions provided, how would the process of 'Admission' differ from the process of an 'Application', and what criteria must a student meet to progress from one to the other?\nGenerated Reply (Flan-T5):\nNot commenced i.e. \"\"\"A\"\"\"\". Offer status\nReference Answer:\n\"Application is Applicant's instruction to be considered for a programme of study by submitting an application form\nBLEU Score: 0\nMemory Usage: 2510.16 MB\nTime taken for this query: 3.59 seconds\n\nRunning with T5-Small Model\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the definition of 'Articulation'?\nGenerated Reply (T5-Small):\n'Articulation'? Relevant information: FAISS info: Articulation is Arrangements enabling students to progress from a completed qualification to another with admission and/or credit in a defined qualification pathway Or qualifying to enter the Bachelor program.\nReference Answer:\nArticulation is Arrangements enabling students to progress from a completed qualification to another with admission and/or credit in a defined qualification pathway  Or qualifying to enter the Bachelor program. created by TEQSA\nBLEU Score: 0.8459547884985757\nMemory Usage: 2569.15 MB\nTime taken for this query: 4.08 seconds\n\nQuery: Which accreditation framework is mentioned under the definition of 'Doctoral Degree'?\nGenerated Reply (T5-Small):\na major research component: comprised of two-thirds or more research leading to a thesis/dissertation OR qualifies individuals who apply a substantial body of knowledge to research, investigate and develop new knowledge. Designed and accredited to enable graduates to demonstrate the learning outcomes specified in the level 10 criteria and the Doctoral Degree descriptor. Graduate Certificate qualifications are available for accreditation and issuance in both higher education and vocational education and training.\nReference Answer:\n\"Doctoral Degree is Course with major research component: comprised of two-thirds or more research leading to a thesis/dissertation OR qualifies individuals who apply a substantial body of knowledge to research, investigate and develop new knowledge, in one or more fields of investigation, scholarship or professional practice. Two forms of Doctoral Degree with the same descriptor within the Doctoral Degree qualification type: the Doctoral Degree (Research) and the Doctoral Degree (Professional). Research is the defining characteristic of all Doctoral Degree qualifications. The research Doctoral Degree (typically referred to as a Doctor of Philosophy) makes a significant and original contribution to knowledge; the professional Doctoral Degree (typically titled Doctor of [field of study]) makes a significant and original contribution to knowledge in the context of professional practice. Learning outcomes and research may differ between the different forms of Doctoral Degree qualifications. Designed and accredited to enable graduates to demonstrate the learning outcomes specified in the level 10 criteria and the Doctoral Degree. created by AQF (Australian Qualifications Framework)\"\nBLEU Score: 0.1815209518783796\nMemory Usage: 2519.93 MB\nTime taken for this query: 7.35 seconds\n\nQuery: Which organization is referenced in the definition of 'Assessment'?\nGenerated Reply (T5-Small):\nwhich organization is referenced in the definition of 'Assessment'? Which organization is referenced in the definition of 'Assessment'? Relevant information: FAISS info: \"Assessment is Assessment is the process of appraising, evaluating and making a judgment about someone's knowledge, skills and ability in order to determine if they have met with and achieved the designated learning outcomes of individual units of study\"\nReference Answer:\n\"Assessment is Assessment is the process of appraising, evaluating and making a judgment about someone's knowledge, skills and ability in order to determine if they have met with and achieved the designated learning outcomes of individual units of study.\nBLEU Score: 0.6132657262072154\nMemory Usage: 2522.54 MB\nTime taken for this query: 6.60 seconds\n\nQuery: What is the difference between a 'Bachelor Degree' and a 'Bachelor Honours Degree' with reference to qualification level in the AQF?\nGenerated Reply (T5-Small):\nto undertake professional work and as a pathway for further learning. Instruction: What is the difference between a 'Bachelor Degree' and a 'Bachelor Honours Degree' with reference to qualification level in the AQF? Relevant information: FAISS info: \"Bachelor Honours Degree is Qualifies individuals who apply a body of knowledge in a specific context to undertake professional work and as a pathway for further learning\nReference Answer:\n\"Bachelor Honours Degree is Qualifies individuals who apply a body of knowledge in a specific context to undertake professional work and as a pathway for research and further learning. Bachelor Honours Degree qualifications are located at level 8 of the Australian Qualifications Framework. Qualifications must be designed and accredited to enable graduates to demonstrate the learning outcomes expressed as knowledge, skills and the application of knowledge and skills specified in the level 8 criteria and the Bachelor Degree descriptor. created by AQF (Australian Qualifications Framework)\"\nBLEU Score: 0.3064880009506149\nMemory Usage: 2523.13 MB\nTime taken for this query: 7.32 seconds\n\nQuery: If a student studies in a foreign educational institution and is not a citizen or permanent resident of Australia, what term would the dataset use to categorize them as per the definitions?\nGenerated Reply (T5-Small):\n: Students who study in a foreign educational institution. In Australia you are considered to be an overseas student if you’re not an Australian citizen \"International Student is Any student who is not a domestic student OR a student who is NOT one of the following: Destination Provider home Location Citizen, Destination Provider home Location permanent, humanitarian visa holder, Destination Provider home Location holder of a permanent visa other than a permanent humanitarian visa\"\nReference Answer:\nStudents who study in foreign educational institutions. In Australia you are considered to be an overseas student if you’re not an Australian citizen\nBLEU Score: 0.24130688796907232\nMemory Usage: 2517.95 MB\nTime taken for this query: 6.35 seconds\n\nQuery: If a student completes a Certificate III and intends to directly pursue a Bachelor Degree, which concept from this dataset would likely apply to their transition?\nGenerated Reply (T5-Small):\nto pursue a Bachelor Degree? is the same as the TEQSA definition in that it signals the progress of a student through their defined course of study or pathway. Instruction: If a student completes a Certificate III and intends to directly pursue a Bachelor Degree, which concept from this dataset would likely apply to their transition? Relevant information: FAISS info: \"Certificate III is Qualifies individuals who apply a broad range\nReference Answer:\n\"Certificate III is Qualifies individuals who apply a broad range of knowledge and skills in varied contexts to undertake skilled work and as a pathway for further learning. Designed and accredited to enable graduates to demonstrate the learning outcomes expressed as knowledge, skills and the application of knowledge and skills specified in the level 3 criteria and the Certificate III descriptor. created by AQF (Australian Qualifications Framework)\"\nBLEU Score: 0.15720527174368754\nMemory Usage: 2523.06 MB\nTime taken for this query: 6.74 seconds\n\nQuery: Describe the relationship between 'Foundation Course' and 'Pathway Course' based on their respective definitions.\nGenerated Reply (T5-Small):\nif a student fails to meet the academic requirements for entry to the Diploma; or, direct entry to a Diploma course if they meet both the English language and the academic requirements for entry to the Diploma. Instruction: Describe the relationship between 'Foundation Course' and 'Pathway Course' based on their respective definitions. Instruction: Describe the relationship between 'Foundation Course' and 'Pathway\nReference Answer:\n\"Pathway Course is An award or non-award course/program that a student completes ahead of access to a subsequent course (e.g. ELICOS ahead of Foundation Program; diploma ahead of degree, undergraduate degree ahead of postgraduate degree etc).  Pathway courses/programs typically include: ELICOS, Foundation, Diploma, Pre-Masters, but may also include other sub-bachelor courses such as associate degrees. created by TEQSA\"\nBLEU Score: 0.01611644699178665\nMemory Usage: 2679.40 MB\nTime taken for this query: 7.73 seconds\n\nQuery: What percentage of modules studied that received a pass grade is referred to in the dataset, and under what name is this metric captured?\nGenerated Reply (T5-Small):\n: What percentage of modules studied that received a pass grade is referred to in the dataset. Instruction: What percentage of modules studied that received a pass grade is referred to in the dataset. Instruction: What percentage of modules studied that received a pass grade is referred to in the dataset, and under what name is this metric captured?\nReference Answer:\nAssessment Result is The mark given for an assessment item created by The University of Western Australia\nBLEU Score: 0.006276214076282571\nMemory Usage: 2679.43 MB\nTime taken for this query: 5.33 seconds\n\nQuery: If a student qualifies under the 'Doctoral Degree (Research)' category of the AQF, what learning outcome is significant in their qualification process?\nGenerated Reply (T5-Small):\nin the 'Doctoral Degree (Research)' category of the AQF, what learning outcome is significant in their qualification process? Relevant information: FAISS info: \"Doctoral Degree is Course with major research component: comprised of two-thirds or more research leading to a thesis/dissertation\" \"Bachelor Degree is Qualifies individuals who apply integrated technical and theoretical concepts in a broad range of contexts to undertake advanced\nReference Answer:\n\"Doctoral Degree is Course with major research component: comprised of two-thirds or more research leading to a thesis/dissertation OR qualifies individuals who apply a substantial body of knowledge to research, investigate and develop new knowledge, in one or more fields of investigation, scholarship or professional practice. Two forms of Doctoral Degree with the same descriptor within the Doctoral Degree qualification type: the Doctoral Degree (Research) and the Doctoral Degree (Professional). Research is the defining characteristic of all Doctoral Degree qualifications. The research Doctoral Degree (typically referred to as a Doctor of Philosophy) makes a significant and original contribution to knowledge; the professional Doctoral Degree (typically titled Doctor of [field of study]) makes a significant and original contribution to knowledge in the context of professional practice. Learning outcomes and research may differ between the different forms of Doctoral Degree qualifications. Designed and accredited to enable graduates to demonstrate the learning outcomes specified in the level 10 criteria and the Doctoral Degree. created by AQF (Australian Qualifications Framework)\"\nBLEU Score: 0.05947434694077391\nMemory Usage: 2688.51 MB\nTime taken for this query: 6.70 seconds\n\nQuery: Based on the definitions provided, how would the process of 'Admission' differ from the process of an 'Application', and what criteria must a student meet to progress from one to the other?\nGenerated Reply (T5-Small):\nthe process of 'Admission' differ from the process of an 'Application', and what criteria must a student meet to progress from one to the other? Relevant information: FAISS info: \"Admission is Student's admission into a program, covering the point of admission and record of ongoing status of their admission\" Does not include rejected. \"Admission is Student's admission into a program, covering the point of admission\nReference Answer:\n\"Application is Applicant's instruction to be considered for a programme of study by submitting an application form\nBLEU Score: 0.007272909189545273\nMemory Usage: 2523.09 MB\nTime taken for this query: 7.15 seconds\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-8416d425d19b4c23aac172355dfdd152\", \"tr-4bb9b4e994d8431fa3f4ed2e1726bb57\", \"tr-11c0dadd9a89421db2743504c5825517\", \"tr-f5817a55deb548cdaad1781fc6f15cae\", \"tr-b0a117bcd3a94022a9a96c99220169cf\", \"tr-eed4b9cca9394854ac742602bd8e11fd\", \"tr-3c733ef4488b4dfd9c0cb600a3d19a3f\", \"tr-3da249f9f9574c0388e4a44d5be49634\", \"tr-c8a7ede2726043018ca68e5c94b7acf0\", \"tr-eccb726f306d4172b83f43f391d4e4c2\"]",
      "text/plain": [
       "[Trace(request_id=tr-8416d425d19b4c23aac172355dfdd152), Trace(request_id=tr-4bb9b4e994d8431fa3f4ed2e1726bb57), Trace(request_id=tr-11c0dadd9a89421db2743504c5825517), Trace(request_id=tr-f5817a55deb548cdaad1781fc6f15cae), Trace(request_id=tr-b0a117bcd3a94022a9a96c99220169cf), Trace(request_id=tr-eed4b9cca9394854ac742602bd8e11fd), Trace(request_id=tr-3c733ef4488b4dfd9c0cb600a3d19a3f), Trace(request_id=tr-3da249f9f9574c0388e4a44d5be49634), Trace(request_id=tr-c8a7ede2726043018ca68e5c94b7acf0), Trace(request_id=tr-eccb726f306d4172b83f43f391d4e4c2)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "import time\n",
    "import psutil\n",
    "from functools import lru_cache\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load definitions and KG\n",
    "    definitions = load_definitions('ctx_pd.txt')\n",
    "    \n",
    "    # Load the knowledge graph\n",
    "    kg = nx.read_gml('kg_graph.gml')\n",
    "    \n",
    "    # Initialize the retriever (with KG and FAISS)\n",
    "    retriever = KGAndFAISSRetriever(definitions, kg, num_retrieved_docs=5)\n",
    "\n",
    "    # Sample queries\n",
    "    generated_queries = [\n",
    "        \"What is the definition of 'Articulation'?\",\n",
    "        \"Which accreditation framework is mentioned under the definition of 'Doctoral Degree'?\",\n",
    "        \"Which organization is referenced in the definition of 'Assessment'?\",\n",
    "        \"What is the difference between a 'Bachelor Degree' and a 'Bachelor Honours Degree' with reference to qualification level in the AQF?\",\n",
    "        \"If a student studies in a foreign educational institution and is not a citizen or permanent resident of Australia, what term would the dataset use to categorize them as per the definitions?\",\n",
    "        \"If a student completes a Certificate III and intends to directly pursue a Bachelor Degree, which concept from this dataset would likely apply to their transition?\",\n",
    "        \"Describe the relationship between 'Foundation Course' and 'Pathway Course' based on their respective definitions.\",\n",
    "        \"What percentage of modules studied that received a pass grade is referred to in the dataset, and under what name is this metric captured?\",\n",
    "        \"If a student qualifies under the 'Doctoral Degree (Research)' category of the AQF, what learning outcome is significant in their qualification process?\",\n",
    "        \"Based on the definitions provided, how would the process of 'Admission' differ from the process of an 'Application', and what criteria must a student meet to progress from one to the other?\"\n",
    "    ]\n",
    "\n",
    "    ### Run queries using `FlanT5Assistant`\n",
    "    print(\"Running with Flan-T5-Small Model\")\n",
    "    assistant_flan = FlanT5Assistant(model_name='google/flan-t5-small')\n",
    "\n",
    "    for query in generated_queries:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Retrieve from both FAISS and KG\n",
    "        faiss_docs, kg_info = retriever.search(query)\n",
    "        faiss_info = \" \".join([doc.page_content for doc in faiss_docs])\n",
    "        retrieved_info = f\"FAISS info: {faiss_info}\\nKG info: {kg_info}\"\n",
    "\n",
    "        # Find the reference answer\n",
    "        reference_answer = faiss_docs[0].page_content if faiss_docs else \"\"\n",
    "        \n",
    "        # Generate reply\n",
    "        generated_reply = cached_generate_reply(assistant_flan, query, retrieved_info)\n",
    "\n",
    "        # Calculate BLEU score\n",
    "        if reference_answer:\n",
    "            bleu_score = calculate_bleu(reference_answer, generated_reply)\n",
    "        else:\n",
    "            bleu_score = \"N/A\"\n",
    "\n",
    "        # Output the results\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Generated Reply (Flan-T5):\\n{generated_reply}\")\n",
    "        print(f\"Reference Answer:\\n{reference_answer}\")\n",
    "        print(f\"BLEU Score: {bleu_score}\")\n",
    "\n",
    "        print_memory_usage()\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken for this query: {end_time - start_time:.2f} seconds\\n\")\n",
    "\n",
    "    ### Run queries using `T5Assistant`\n",
    "    print(\"Running with T5-Small Model\")\n",
    "    assistant_t5 = T5Assistant(model_name='t5-small')\n",
    "\n",
    "    for query in generated_queries:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Retrieve from both FAISS and KG\n",
    "        faiss_docs, kg_info = retriever.search(query)\n",
    "        faiss_info = \" \".join([doc.page_content for doc in faiss_docs])\n",
    "        retrieved_info = f\"FAISS info: {faiss_info}\\nKG info: {kg_info}\"\n",
    "\n",
    "        # Find the reference answer\n",
    "        reference_answer = faiss_docs[0].page_content if faiss_docs else \"\"\n",
    "        \n",
    "        # Generate reply\n",
    "        generated_reply = cached_generate_reply(assistant_t5, query, retrieved_info)\n",
    "\n",
    "        # Calculate BLEU score\n",
    "        if reference_answer:\n",
    "            bleu_score = calculate_bleu(reference_answer, generated_reply)\n",
    "        else:\n",
    "            bleu_score = \"N/A\"\n",
    "\n",
    "        # Output the results\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Generated Reply (T5-Small):\\n{generated_reply}\")\n",
    "        print(f\"Reference Answer:\\n{reference_answer}\")\n",
    "        print(f\"BLEU Score: {bleu_score}\")\n",
    "\n",
    "        print_memory_usage()\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken for this query: {end_time - start_time:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8413cbf-9a24-4c3a-aa3f-dee50bdc2f0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison table saved to comparison_table.csv\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Generated Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the definition of 'Articulation'?</td>\n",
       "      <td>KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which accreditation framework is mentioned und...</td>\n",
       "      <td>professional or highly skilled work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which organization is referenced in the defini...</td>\n",
       "      <td>Assessment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the difference between a 'Bachelor Deg...</td>\n",
       "      <td>Bachelor Honours Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If a student studies in a foreign educational ...</td>\n",
       "      <td>KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If a student completes a Certificate III and i...</td>\n",
       "      <td>Bachelor degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Describe the relationship between 'Foundation ...</td>\n",
       "      <td>Foundation Course)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What percentage of modules studied that receiv...</td>\n",
       "      <td>Assessment Result is the mark given for an ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If a student qualifies under the 'Doctoral Deg...</td>\n",
       "      <td>Diploma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Based on the definitions provided, how would t...</td>\n",
       "      <td>Not commenced i.e. \"\"\"A\"\"\"\". Offer status</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query                                    Generated Reply\n",
       "0          What is the definition of 'Articulation'?                                                 KG\n",
       "1  Which accreditation framework is mentioned und...                professional or highly skilled work\n",
       "2  Which organization is referenced in the defini...                                         Assessment\n",
       "3  What is the difference between a 'Bachelor Deg...                            Bachelor Honours Degree\n",
       "4  If a student studies in a foreign educational ...                                                 KG\n",
       "5  If a student completes a Certificate III and i...                                    Bachelor degree\n",
       "6  Describe the relationship between 'Foundation ...                                 Foundation Course)\n",
       "7  What percentage of modules studied that receiv...  Assessment Result is the mark given for an ass...\n",
       "8  If a student qualifies under the 'Doctoral Deg...                                            Diploma\n",
       "9  Based on the definitions provided, how would t...          Not commenced i.e. \"\"\"A\"\"\"\". Offer status"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-41683e31064f4cfe836510a1780b123d\", \"tr-46bc7b4a7dd747b4955c8556abd2fdf2\", \"tr-7e1d92af08374981a568260d1eb2afa3\", \"tr-1fd89d5d67c6417893726de9cdd8d64e\", \"tr-3157b9226f5846958b4cb5463ebd8363\", \"tr-d6786062086e4c91a1a776ecd8cdd6ae\", \"tr-5886b034d2584f4f8381f53668865e38\", \"tr-9de1a267bcce4c44a9a195c181d0713d\", \"tr-94ad3e009c5044aaaf5b0e011e10cf94\", \"tr-ce6b4f57046745519b2375076b7d2c0e\"]",
      "text/plain": [
       "[Trace(request_id=tr-41683e31064f4cfe836510a1780b123d), Trace(request_id=tr-46bc7b4a7dd747b4955c8556abd2fdf2), Trace(request_id=tr-7e1d92af08374981a568260d1eb2afa3), Trace(request_id=tr-1fd89d5d67c6417893726de9cdd8d64e), Trace(request_id=tr-3157b9226f5846958b4cb5463ebd8363), Trace(request_id=tr-d6786062086e4c91a1a776ecd8cdd6ae), Trace(request_id=tr-5886b034d2584f4f8381f53668865e38), Trace(request_id=tr-9de1a267bcce4c44a9a195c181d0713d), Trace(request_id=tr-94ad3e009c5044aaaf5b0e011e10cf94), Trace(request_id=tr-ce6b4f57046745519b2375076b7d2c0e)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the function to create a comparison table\n",
    "def create_comparison_table(queries, generated_replies, file_name=\"comparison_table.csv\"):\n",
    "    # Create a DataFrame with the queries and generated replies\n",
    "    data = {\n",
    "        \"Query\": queries,\n",
    "        \"Generated Reply\": generated_replies\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f\"Comparison table saved to {file_name}\")\n",
    "    return df\n",
    "\n",
    "# Initialize an empty list for the generated replies\n",
    "generated_replies = []\n",
    "\n",
    "# Assuming `generated_queries` contains your sample queries\n",
    "for query in generated_queries:\n",
    "    # Retrieve from both FAISS and KG\n",
    "    faiss_docs, kg_info = retriever.search(query)\n",
    "    faiss_info = \" \".join([doc.page_content for doc in faiss_docs])\n",
    "    \n",
    "    # Generate reply\n",
    "    retrieved_info = f\"FAISS info: {faiss_info}\\nKG info: {kg_info}\"\n",
    "    generated_reply = cached_generate_reply(assistant, query, retrieved_info)\n",
    "    \n",
    "    # Store the generated reply\n",
    "    generated_replies.append(generated_reply)\n",
    "\n",
    "# Now that `generated_replies` are collected, we can create the comparison table\n",
    "create_comparison_table(generated_queries, generated_replies)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "KG+RAG(T5small+flanT5)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
